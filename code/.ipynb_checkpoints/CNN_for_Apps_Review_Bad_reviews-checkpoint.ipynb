{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_H21rwwt00lK"
   },
   "source": [
    "# Shopping Apps, Rating for Google Play Store and Apple AppStore Users\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Users download apps for various purposes. Given that there is a rise in the usage of online shopping due to the Covid-19 pandemic, improvement of shopping experience has become more important then before. With that in mind, what are the important features we have to look out for to improve a shopping app?\n",
    "\n",
    "More specifically, the questions to be answered:\n",
    "\n",
    "- How do the app ratings differ across different shopping apps?\n",
    "- Is there any specific group of users we can look out for to improve the app?\n",
    "- Are there any specific improvement we can work on to further improve user experience of the app?\n",
    "\n",
    "To explore and answer the above questions, we will scrap reviews from Google Play Store and Apple AppStore and conduct analysis and modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "2MZhvHZb00lK"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef, confusion_matrix, roc_auc_score, plot_roc_curve, plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report, roc_curve, cohen_kappa_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer                    \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, Embedding, Conv1D, GlobalMaxPooling1D, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow import concat\n",
    "from tensorflow.keras.metrics import Accuracy, CategoricalAccuracy, CosineSimilarity\n",
    "from tensorflow.keras.regularizers import l1_l2, l2, l1\n",
    "from tensorflow.math import confusion_matrix\n",
    "from tensorflow_addons.metrics import CohenKappa, MatthewsCorrelationCoefficient, F1Score, MultiLabelConfusionMatrix\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0ipV3s7_00lN"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/reviews_Model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "GHyaWA4X00lQ",
    "outputId": "e8f42763-4d37-460c-fca2-8bf184c064a7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>app</th>\n",
       "      <th>store</th>\n",
       "      <th>review</th>\n",
       "      <th>clean_content</th>\n",
       "      <th>adj</th>\n",
       "      <th>noun</th>\n",
       "      <th>verb</th>\n",
       "      <th>emoji</th>\n",
       "      <th>...</th>\n",
       "      <th>pos_score</th>\n",
       "      <th>compound_score</th>\n",
       "      <th>language</th>\n",
       "      <th>month</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>text_len</th>\n",
       "      <th>word_count</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2020-09-16 20:26:28</td>\n",
       "      <td>shoppee</td>\n",
       "      <td>google</td>\n",
       "      <td>Orders mostly came early and products are good.</td>\n",
       "      <td>order come early product good</td>\n",
       "      <td>good</td>\n",
       "      <td>order product</td>\n",
       "      <td>come</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>en</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>47</td>\n",
       "      <td>8</td>\n",
       "      <td>Delivery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-09-16 20:13:46</td>\n",
       "      <td>shoppee</td>\n",
       "      <td>google</td>\n",
       "      <td>Good and convenient</td>\n",
       "      <td>good convenient</td>\n",
       "      <td>good convenient</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>en</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>Convenient App</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-09-16 20:11:18</td>\n",
       "      <td>shoppee</td>\n",
       "      <td>google</td>\n",
       "      <td>My first purchase experience...Happy with purc...</td>\n",
       "      <td>purchase experience happy purchase thks</td>\n",
       "      <td>first happy</td>\n",
       "      <td>purchase experience purchase</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>en</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>Consumer Satisfaction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2020-09-16 20:08:54</td>\n",
       "      <td>shoppee</td>\n",
       "      <td>google</td>\n",
       "      <td>A lot of items at a very good deal.</td>\n",
       "      <td>lot item good deal</td>\n",
       "      <td>good</td>\n",
       "      <td>lot item deal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.4927</td>\n",
       "      <td>en</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>Variety &amp; Price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2020-09-16 19:37:21</td>\n",
       "      <td>shoppee</td>\n",
       "      <td>google</td>\n",
       "      <td>Delivery is fast</td>\n",
       "      <td>delivery fast</td>\n",
       "      <td>fast</td>\n",
       "      <td>delivery</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>en</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>37</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>Delivery</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                 date      app   store  \\\n",
       "0       5  2020-09-16 20:26:28  shoppee  google   \n",
       "1       4  2020-09-16 20:13:46  shoppee  google   \n",
       "2       4  2020-09-16 20:11:18  shoppee  google   \n",
       "3       5  2020-09-16 20:08:54  shoppee  google   \n",
       "4       5  2020-09-16 19:37:21  shoppee  google   \n",
       "\n",
       "                                              review  \\\n",
       "0    Orders mostly came early and products are good.   \n",
       "1                                Good and convenient   \n",
       "2  My first purchase experience...Happy with purc...   \n",
       "3                A lot of items at a very good deal.   \n",
       "4                                   Delivery is fast   \n",
       "\n",
       "                             clean_content               adj  \\\n",
       "0            order come early product good             good    \n",
       "1                          good convenient  good convenient    \n",
       "2  purchase experience happy purchase thks      first happy    \n",
       "3                       lot item good deal             good    \n",
       "4                            delivery fast             fast    \n",
       "\n",
       "                            noun   verb emoji  ...  pos_score  compound_score  \\\n",
       "0                 order product   come    NaN  ...      0.293          0.4404   \n",
       "1                            NaN    NaN   NaN  ...      0.592          0.4404   \n",
       "2  purchase experience purchase     NaN   NaN  ...      0.286          0.3400   \n",
       "3                 lot item deal     NaN   NaN  ...      0.285          0.4927   \n",
       "4                      delivery     NaN   NaN  ...      0.000          0.0000   \n",
       "\n",
       "   language  month dayofweek  hour  minute  text_len  word_count  \\\n",
       "0        en      9         3    20      26        47           8   \n",
       "1        en      9         3    20      13        19           3   \n",
       "2        en      9         3    20      11        57           7   \n",
       "3        en      9         3    20       8        35           9   \n",
       "4        en      9         3    19      37        16           3   \n",
       "\n",
       "                category  \n",
       "0               Delivery  \n",
       "1         Convenient App  \n",
       "2  Consumer Satisfaction  \n",
       "3        Variety & Price  \n",
       "4               Delivery  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "dvkP3i9s00lS"
   },
   "outputs": [],
   "source": [
    "#list comprehension for target variable\n",
    "df = df[df['rating'] <= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "id": "RLwT_VQO00lU",
    "outputId": "b9eca17b-55d1-4ae6-ad34-06badd381f72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Account Issues            0.198107\n",
       "App Issues                0.189493\n",
       "Poor In-app Events        0.133468\n",
       "Poor Customer Service     0.095600\n",
       "Payment Issue             0.092419\n",
       "Delivery Issues           0.083029\n",
       "Refund                    0.080624\n",
       "Poor Seller Feedback      0.057345\n",
       "Product Issue             0.049119\n",
       "Product Listing Issues    0.020796\n",
       "Name: category, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "oDzIuqqD00lX",
    "outputId": "60406572-7a2a-49d8-ba5d-989e892ab3a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adj       2872\n",
       "noun       640\n",
       "verb      1159\n",
       "emoji    12267\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking null values\n",
    "df.isna().sum()[df.isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "B0-D3lfF00lZ",
    "outputId": "89c9054c-353c-4f53-f62b-5fa4442444a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values left in df: 0\n",
      "Number of rows left: 12887\n"
     ]
    }
   ],
   "source": [
    "## Removing null values\n",
    "df= df[df['clean_content'].notna()]\n",
    "df.reset_index(drop = True, inplace = True)\n",
    "print(f'Null values left in df: {df.clean_content.isna().sum()}')\n",
    "print(f'Number of rows left: {df.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDOggIIj00lb"
   },
   "source": [
    "## Train Test Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "b2QGbco9UJl_"
   },
   "outputs": [],
   "source": [
    "X = df['clean_content']\n",
    "y = df['category']\n",
    "\n",
    "lb = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "nTIQ8fy300lb"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 42,\n",
    "                                                    stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "aPCFaR3Q00ld",
    "outputId": "a26d113b-525d-49ac-d009-bb5115e689cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train rows: 10309, X_test rows: 2578\n",
      "y_train rows: 10309, y_test rows: 2578\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train rows: {X_train.shape[0]}, X_test rows: {X_test.shape[0]}')\n",
    "print(f'y_train rows: {y_train.shape[0]}, y_test rows: {y_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vc9-2DiE00l7"
   },
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ld0ILnZM7iWM"
   },
   "source": [
    "### Tokenize Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "m51S240tEM_W"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=9000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "# Adding 1 because of  reserved 0 index\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "train_word_index = tokenizer.word_index\n",
    "\n",
    "maxlen = 9000\n",
    "\n",
    "y_train_label = lb.fit_transform(y_train)\n",
    "y_test_label = lb.transform(y_test)\n",
    "\n",
    "y_train_dummy = to_categorical(y_train_label)\n",
    "y_test_dummy = to_categorical(y_test_label)\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "\n",
    "embedding_dim = 100\n",
    "\n",
    "train_embedding_weights = np.zeros((len(train_word_index)+1, embedding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "6aGlsy2mdINh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sim Yi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=['Account Issues' 'App Issues' 'Delivery Issues' 'Payment Issue'\n",
      " 'Poor Customer Service' 'Poor In-app Events' 'Poor Seller Feedback'\n",
      " 'Product Issue' 'Product Listing Issues' 'Refund'], y=11256     Poor Customer Service\n",
      "173              Account Issues\n",
      "5831             Account Issues\n",
      "4767                 App Issues\n",
      "11135     Poor Customer Service\n",
      "                  ...          \n",
      "4064       Poor Seller Feedback\n",
      "7563     Product Listing Issues\n",
      "6937         Poor In-app Events\n",
      "4355                     Refund\n",
      "10104             Payment Issue\n",
      "Name: category, Length: 10309, dtype: object as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    }
   ],
   "source": [
    "weights = class_weight.compute_class_weight('balanced',\n",
    "                                            np.unique(y_train),\n",
    "                                            y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "id": "APBH9hjkdJ6Q",
    "outputId": "f633a9fb-36d6-4c40-e2a9-9dfe9ce50f54"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5048481880509305,\n",
       " 1: 0.5275844421699079,\n",
       " 2: 1.204322429906542,\n",
       " 3: 1.0817418677859392,\n",
       " 4: 1.0455375253549695,\n",
       " 5: 0.7492005813953488,\n",
       " 6: 1.744331641285956,\n",
       " 7: 2.0373517786561264,\n",
       " 8: 4.817289719626168,\n",
       " 9: 1.2405535499398315}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = dict(enumerate(weights))\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dk7Wq72Z7m-0"
   },
   "source": [
    "### Adding Sequence for Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvNet(embeddings, max_sequence_length, num_words, embedding_dim, labels_index):\n",
    " \n",
    "    embedding_layer = Embedding(num_words,\n",
    "                            embedding_dim,\n",
    "                            weights=[embeddings],\n",
    "                            input_length=max_sequence_length,\n",
    "                            trainable=False)\n",
    "    \n",
    "    sequence_input = Input(shape=(max_sequence_length,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    convs = []\n",
    "    filter_sizes = [2,3,4,5,6]\n",
    "    for filter_size in filter_sizes:\n",
    "        l_conv = Conv1D(filters=200, \n",
    "                        kernel_size=filter_size, \n",
    "                        activation='relu')(embedded_sequences)\n",
    "        l_pool = GlobalMaxPooling1D()(l_conv)\n",
    "        convs.append(l_pool)\n",
    "    l_merge = concat(convs, axis=1)\n",
    "    x = Dropout(0.1)(l_merge)  \n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    preds = Dense(labels_index, activation='sigmoid')(x)\n",
    "    model = Model(sequence_input, preds)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 9000)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 9000, 100)    947100      input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 8999, 200)    40200       embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 8998, 200)    60200       embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 8997, 200)    80200       embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 8996, 200)    100200      embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 8995, 200)    120200      embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_20 (Global (None, 200)          0           conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_21 (Global (None, 200)          0           conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_22 (Global (None, 200)          0           conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_23 (Global (None, 200)          0           conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_24 (Global (None, 200)          0           conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_1 (TensorFlo [(None, 1000)]       0           global_max_pooling1d_20[0][0]    \n",
      "                                                                 global_max_pooling1d_21[0][0]    \n",
      "                                                                 global_max_pooling1d_22[0][0]    \n",
      "                                                                 global_max_pooling1d_23[0][0]    \n",
      "                                                                 global_max_pooling1d_24[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1000)         0           tf_op_layer_concat_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          128128      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           1290        dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,477,518\n",
      "Trainable params: 530,418\n",
      "Non-trainable params: 947,100\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ConvNet(train_embedding_weights, \n",
    "                maxlen, \n",
    "                len(train_word_index)+1, \n",
    "                embedding_dim, \n",
    "                10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, \"my_first_model.png\", show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "emQ2FDAv7tff"
   },
   "source": [
    "### Training Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 638
    },
    "id": "IcvsWJFOjI4M",
    "outputId": "1be53ebc-abce-4c31-f284-dc0b659ea284"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 16/323 [>.............................] - ETA: 19:56 - loss: 0.6679 - acc: 0.1973"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-8a0ee469140f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m hist = model.fit(X_train, \n\u001b[0m\u001b[0;32m      4\u001b[0m                  \u001b[0my_train_dummy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                  \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "hist = model.fit(X_train, \n",
    "                 y_train_dummy, \n",
    "                 epochs=num_epochs, \n",
    "                 validation_data = (X_test,y_test_dummy) , \n",
    "                 shuffle=True, \n",
    "                 batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "snoF0h8J7251"
   },
   "source": [
    "### Accuracy of Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "uTz_h4KcCZAC",
    "outputId": "47e69072-b2c6-4dd7-e749-f0cce42012f7"
   },
   "outputs": [],
   "source": [
    "predictions = np.argmax(hist.predict(X_test), axis=-1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "DfgfoYFIql7b",
    "outputId": "1d0476ab-9cd6-460f-df44-baeaf9e909b9"
   },
   "outputs": [],
   "source": [
    "# evaluate\n",
    "loss, acc = hist.evaluate(X_test, y_test_dummy, verbose=0)\n",
    "print('Test Accuracy: %f' % (acc*100))\n",
    "print(f'MCC Score: {matthews_corrcoef(y_test_label, predictions)}')\n",
    "print(f'Kappa Score: {cohen_kappa_score(y_test_label, predictions)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "piyOXdPX8EzY"
   },
   "source": [
    "### Heatmap of Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "id": "aRwr_BKWtbQs",
    "outputId": "919af093-960b-4112-b070-6bf0905db733"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "plt.title('Convolutional Neural Network', fontdict = {'fontsize': 15})\n",
    "ax = sns.heatmap(confusion_matrix(y_test_label, predictions), annot=True, fmt=\"d\", cmap='Oranges')\n",
    "ax.set_ylabel('Actual Value')\n",
    "ax.set_xlabel('Predicted Value');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46CrRHHz8Xut"
   },
   "source": [
    "### Plotting ROC AUC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "koUJOKAy7T4c"
   },
   "source": [
    "### Check Misclassified Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "AlXbhVhNzVbg",
    "outputId": "9e559f90-175e-4404-d1bb-5c914ded489b"
   },
   "outputs": [],
   "source": [
    "lb.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "id": "pJ6ytmE80-9l",
    "outputId": "c4ee3462-cf16-40fc-8896-19f6875bf16b"
   },
   "outputs": [],
   "source": [
    "# Create DataFrame with column for predicted values.\n",
    "results = pd.DataFrame(lb.inverse_transform(predictions), columns=['predicted'], index = y_test.index)\n",
    "\n",
    "# Create column for observed values.\n",
    "results['actual'] = y_test\n",
    "results['review'] = df['review']\n",
    "results['clean_content'] = df['clean_content']\n",
    "\n",
    "# Find all indices where predicted and true results \n",
    "# aren't the same, then save in an array.\n",
    "ms_class = results[results['predicted']!= results['actual']]\n",
    "ms_class.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "LhreZAUt7Fgj",
    "outputId": "e467dd1d-70a2-4d0d-9bd5-0d2940fc8e40"
   },
   "outputs": [],
   "source": [
    "# save model and architecture to single file\n",
    "model.save('/content/drive/My Drive/Colab Notebooks/2.model.h5')\n",
    "print('Saved model to disk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "FPEbGaPii-V0",
    "outputId": "18933161-6229-4b43-b6b1-5348e45a5465"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    " \n",
    "# load model\n",
    "model = load_model('/content/drive/My Drive/Colab Notebooks/2.model.h5')\n",
    "# summarize model.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 864
    },
    "id": "0fqYGdAbBR-3",
    "outputId": "85fcd599-5d0e-4534-b259-ad7facf34b8d"
   },
   "outputs": [],
   "source": [
    "plot_model(model, \"my_first_model.png\", show_shapes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "vFjj1tu5OIUS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN for Apps Review - Bad reviews",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
